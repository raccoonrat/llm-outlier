@article{an2025systematic,
  title={Systematic Outliers in Large Language Models},
  author={An, Yongqi and others},
  journal={arXiv preprint arXiv:2502.06415},
  year={2025}
}

@article{wei2023outlier,
  title={Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling},
  author={Wei, Dong and others},
  journal={Proceedings of the 2023 Conference on Empirical Methods in Natural Language Processing},
  pages={1594--1608},
  year={2023}
}

@article{pucetti2021,
  title={Understanding and mitigating numerical instabilities in transformer language models},
  author={Puccetti, Giulia and others},
  journal={arXiv preprint arXiv:2110.13083},
  year={2021}
}

@article{kovaleva2021,
  title={Understanding and reducing outlier weights in neural networks},
  author={Kovaleva, Olga and others},
  journal={NeurIPS 2021},
  year={2021}
}

@article{dong2025hessian,
  title={Towards Quantifying the Hessian Structure of Neural Networks},
  author={Dong, Li and others},
  journal={arXiv preprint arXiv:2505.02809},
  year={2025}
}

@article{activation_sparsity2025,
  title={Universal Properties of Activation Sparsity in Modern Large Language Models},
  author={Various authors},
  journal={arXiv preprint arXiv:2509.00454},
  year={2025}
}

@article{privacy_auditing2025,
  title={Privacy Auditing of Large Language Models},
  author={Various authors},
  journal={arXiv preprint arXiv:2503.06808},
  year={2025}
}

@article{super_weight_apple,
  title={The "Super Weight:" How Even a Single Parameter can Determine a Large Language Model's Behavior},
  author={Apple Machine Learning Research},
  year={2024}
}

@article{acl_anthology_os_plus,
  title={Outlier Suppression+: Accurate quantization of large language models by equivalent and effective shifting and scaling},
  author={Wei, Dong and others},
  journal={ACL Anthology},
  year={2023}
}

@article{model_compression_survey2025,
  title={A survey of model compression techniques: past, present, and future},
  author={Various authors},
  journal={Frontiers in Robotics and AI},
  year={2025}
}

@article{moonlight_review,
  title={[Literature Review] Systematic Outliers in Large Language Models},
  journal={Moonlight},
  year={2025}
}

@article{liner_review,
  title={[Quick Review] Systematic Outliers in Large Language Models},
  journal={Liner},
  year={2025}
}

@article{unify_ai_compression,
  title={Model Compression: A Survey of Techniques, Tools, and Libraries},
  journal={Unify AI},
  year={2025}
}

@article{mdpi_compression_survey,
  title={Model Compression for Deep Neural Networks: A Survey},
  journal={MDPI},
  volume={12},
  number={3},
  pages={60},
  year={2025}
}

@article{github_systematic_outliers,
  title={[ICLR 2025] Systematic Outliers in Large Language Models},
  url={https://github.com/an-yongqi/systematic-outliers},
  year={2025}
}

@article{diffusion_llm_quantization,
  title={Quantization Meets dLLMs: A Systematic Study of Post-training Quantization for Diffusion LLMs},
  author={Various authors},
  journal={arXiv preprint arXiv:2508.14896},
  year={2025}
}